{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import image as mpimg\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def calculate_accuracy(model, dataloader, device='cpu'):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in dataloader:\n",
    "        images, labels = data\n",
    "\n",
    "        images = images.unsqueeze(1).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes: int = 2, dropout: float = 0.2) -> None:\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def create_classification_dataset(path,\n",
    "                                  crops_per_negative=3,\n",
    "                                  include_mirrors=False):\n",
    "\n",
    "    def extract_patch(image, x_d=64, y_d=128):\n",
    "        x = np.random.randint(0, image.shape[1] - x_d)\n",
    "        y = np.random.randint(0, image.shape[0] - y_d)\n",
    "        patch = image[y: y + y_d, x: x + x_d]\n",
    "\n",
    "        return patch\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for filepath in glob.iglob(f'{path}/negatives/*.png'):\n",
    "        img = mpimg.imread(filepath)\n",
    "        for i in range(crops_per_negative):\n",
    "            p = extract_patch(img)\n",
    "            x.append(p)\n",
    "            y.append(0)\n",
    "\n",
    "    for filepath in glob.iglob(f'{path}/positives/*.png'):\n",
    "        if 'mirr0r' in filepath and not include_mirrors:\n",
    "            pass\n",
    "        img = mpimg.imread(filepath)\n",
    "        x.append(img)\n",
    "        y.append(1)\n",
    "\n",
    "    return np.asarray(x), np.asarray(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "x, y = create_classification_dataset('dataset/asl_eth_flir/flir_17_Sept_2013/train', 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "x = x / x.max()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "x_train = torch.tensor(x_train)\n",
    "x_test = torch.tensor(x_test)\n",
    "\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "test_dataset = TensorDataset(x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.032\n",
      "0.7428523092539333\n",
      "0.7324086603518268\n",
      "[1,   200] loss: 0.023\n",
      "0.8917272881069193\n",
      "0.8778755074424899\n",
      "[1,   300] loss: 0.015\n",
      "0.8934190492302487\n",
      "0.8900541271989174\n",
      "[1,   400] loss: 0.016\n",
      "0.8555236000676705\n",
      "0.8521650879566982\n",
      "[1,   500] loss: 0.015\n",
      "0.9189646421925224\n",
      "0.9191474966170501\n",
      "[1,   600] loss: 0.010\n",
      "0.9328370834038234\n",
      "0.9316644113667117\n",
      "[1,   700] loss: 0.013\n",
      "0.8602605312129927\n",
      "0.8616373477672531\n",
      "[2,   100] loss: 0.015\n",
      "0.8993402131619015\n",
      "0.892083897158322\n",
      "[2,   200] loss: 0.012\n",
      "0.8995939773304009\n",
      "0.9018944519621109\n",
      "[2,   300] loss: 0.011\n",
      "0.9510235154796143\n",
      "0.9502706359945873\n",
      "[2,   400] loss: 0.009\n",
      "0.8743021485366266\n",
      "0.8633288227334236\n",
      "[2,   500] loss: 0.007\n",
      "0.9613432583319236\n",
      "0.9573748308525034\n",
      "[2,   600] loss: 0.011\n",
      "0.9300456775503299\n",
      "0.9272665764546685\n",
      "[2,   700] loss: 0.010\n",
      "0.9566063271866012\n",
      "0.9566982408660352\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model = AlexNet().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        model.train()\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.unsqueeze(1).to(device)\n",
    "        labels = labels.to(device)\n",
    "        # print(inputs.shape)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        # print(labels, outputs.argmax(-1), loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "            print(calculate_accuracy(model, trainloader, device=device))\n",
    "            print(calculate_accuracy(model, testloader, device=device))\n",
    "\n",
    "print('Finished Training')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "from torchattacks.attack import Attack\n",
    "\n",
    "\n",
    "class Pixle(Attack):\n",
    "    r\"\"\"\n",
    "    Pixle: a fast and effective black-box attack based on rearranging pixels'\n",
    "    [https://arxiv.org/abs/2202.02236]\n",
    "\n",
    "    Distance Measure : L0\n",
    "\n",
    "    Arguments:\n",
    "        model (nn.Module): model to attack.\n",
    "        x_dimensions (int or float, or a tuple containing a combination of those): size of the sampled patch along ther x side for each iteration. The integers are considered as fixed number of size,\n",
    "        while the float as parcentage of the size. A tuple is used to specify both under and upper bound of the size. (Default: (2, 10))\n",
    "        y_dimensions (int or float, or a tuple containing a combination of those): size of the sampled patch along ther y side for each iteration. The integers are considered as fixed number of size,\n",
    "        while the float as parcentage of the size. A tuple is used to specify both under and upper bound of the size. (Default: (2, 10))\n",
    "        pixel_mapping (str): the type of mapping used to move the pixels. Can be: 'random', 'similarity', 'similarity_random', 'distance', 'distance_random' (Default: random)\n",
    "        restarts (int): the number of restarts that the algortihm performs. (Default: 20)\n",
    "        max_iterations (int): number of iterations to perform for each restart. (Default: 100)\n",
    "        update_each_iteration (bool): if the attacked images must be modified after each iteration (True) or after each restart (False).  (Default: False)\n",
    "    Shape:\n",
    "        - images: :math:`(N, C, H, W)` where `N = number of batches`, `C = number of channels`,        `H = height` and `W = width`. It must have a range [0, 1].\n",
    "        - labels: :math:`(N)` where each value :math:`y_i` is :math:`0 \\leq y_i \\leq` `number of labels`.\n",
    "        - output: :math:`(N, C, H, W)`.\n",
    "\n",
    "    Examples::\n",
    "        >>> attack = torchattacks.Pixle(model, x_dimensions=(0.1, 0.2), restarts=100, iteratsion=50)\n",
    "        >>> adv_images = attack(images, labels)\n",
    "    \"\"\"\n",
    "    def __init__(self, model, x_dimensions=(2, 10), y_dimensions=(2, 10),\n",
    "                 pixel_mapping='random', restarts=20,\n",
    "                 max_iterations=100, update_each_iteration=False):\n",
    "        super().__init__(\"Pixle\", model)\n",
    "\n",
    "        if restarts < 0 or not isinstance(restarts, int):\n",
    "            raise ValueError('restarts must be and integer >= 0 '\n",
    "                             '({})'.format(restarts))\n",
    "\n",
    "        self.update_each_iteration = update_each_iteration\n",
    "        self.max_patches = max_iterations\n",
    "\n",
    "        self.restarts = restarts\n",
    "        self.pixel_mapping = pixel_mapping.lower()\n",
    "\n",
    "        if self.pixel_mapping not in ['random', 'similarity',\n",
    "                                      'similarity_random', 'distance',\n",
    "                                      'distance_random']:\n",
    "            raise ValueError('pixel_mapping must be one of [random, similarity,'\n",
    "                             'similarity_random, distance, distance_random]'\n",
    "                             ' ({})'.format(self.pixel_mapping))\n",
    "\n",
    "        if isinstance(y_dimensions, (int, float)):\n",
    "            y_dimensions = [y_dimensions, y_dimensions]\n",
    "\n",
    "        if isinstance(x_dimensions, (int, float)):\n",
    "            x_dimensions = [x_dimensions, x_dimensions]\n",
    "\n",
    "        if not all([(isinstance(d, (int)) and d > 0)\n",
    "                    or (isinstance(d, float) and 0 <= d <= 1)\n",
    "                    for d in chain(y_dimensions, x_dimensions)]):\n",
    "            raise ValueError('dimensions of first patch must contains integers'\n",
    "                             ' or floats in [0, 1]'\n",
    "                             ' ({})'.format(y_dimensions))\n",
    "\n",
    "        self.p1_x_dimensions = x_dimensions\n",
    "        self.p1_y_dimensions = y_dimensions\n",
    "\n",
    "        self._supported_mode = ['default', 'targeted']\n",
    "\n",
    "    def forward(self, images, labels):\n",
    "        if not self.update_each_iteration:\n",
    "            return self.restart_forward(images, labels)\n",
    "        else:\n",
    "            return self.iterative_forward(images, labels)\n",
    "\n",
    "    def restart_forward(self, images, labels):\n",
    "        assert len(images.shape) == 3 or \\\n",
    "               (len(images.shape) == 4 and images.size(0) == 1)\n",
    "\n",
    "        if len(images.shape) == 3:\n",
    "            images = images.unsqueeze(0)\n",
    "\n",
    "        if self._targeted:\n",
    "            labels = self._get_target_label(images, labels)\n",
    "\n",
    "        x_bounds = tuple(\n",
    "            [max(1, d if isinstance(d, int) else round(images.size(3) * d))\n",
    "             for d in self.p1_x_dimensions])\n",
    "\n",
    "        y_bounds = tuple(\n",
    "            [max(1, d if isinstance(d, int) else round(images.size(2) * d))\n",
    "             for d in self.p1_y_dimensions])\n",
    "\n",
    "        adv_images = []\n",
    "\n",
    "        images = images.clone().detach().to(self.device)\n",
    "        labels = labels.clone().detach().to(self.device)\n",
    "\n",
    "        bs, _, _, _ = images.shape\n",
    "\n",
    "        for idx in range(bs):\n",
    "            image, label = images[idx:idx + 1], labels[idx:idx + 1]\n",
    "\n",
    "            best_image = image.clone()\n",
    "            pert_image = image.clone()\n",
    "\n",
    "            loss, callback = self._get_fun(image, label,\n",
    "                                           target_attack=self._targeted)\n",
    "            best_solution = None\n",
    "\n",
    "            best_p = loss(solution=image, solution_as_perturbed=True)\n",
    "            image_probs = [best_p]\n",
    "\n",
    "            it = 0\n",
    "\n",
    "            for r in range(self.restarts):\n",
    "                stop = False\n",
    "\n",
    "                for it in range(self.max_patches):\n",
    "\n",
    "                    (x, y), (x_offset, y_offset) = \\\n",
    "                        self.get_patch_coordinates(image=image,\n",
    "                                                   x_bounds=x_bounds,\n",
    "                                                   y_bounds=y_bounds)\n",
    "\n",
    "                    destinations = self.get_pixel_mapping(image, x, x_offset,\n",
    "                                                          y, y_offset,\n",
    "                                                          destination_image=\n",
    "                                                          best_image)\n",
    "\n",
    "                    solution = [x, y, x_offset, y_offset] + destinations\n",
    "\n",
    "                    pert_image = self._perturb(source=image,\n",
    "                                               destination=best_image,\n",
    "                                               solution=solution)\n",
    "\n",
    "                    p = loss(solution=pert_image,\n",
    "                             solution_as_perturbed=True)\n",
    "\n",
    "                    if p < best_p:\n",
    "                        best_p = p\n",
    "                        best_solution = pert_image\n",
    "\n",
    "                    image_probs.append(best_p)\n",
    "\n",
    "                    if callback(pert_image, None, True):\n",
    "                        best_solution = pert_image\n",
    "                        stop = True\n",
    "                        break\n",
    "\n",
    "                if best_solution is None:\n",
    "                    best_image = pert_image\n",
    "                else:\n",
    "                    best_image = best_solution\n",
    "\n",
    "                if stop:\n",
    "                    break\n",
    "\n",
    "            adv_images.append(best_image)\n",
    "\n",
    "        adv_images = torch.cat(adv_images)\n",
    "\n",
    "        return adv_images\n",
    "\n",
    "    def iterative_forward(self, images, labels):\n",
    "        assert len(images.shape) == 3 or \\\n",
    "               (len(images.shape) == 4 and images.size(0) == 1)\n",
    "\n",
    "        if len(images.shape) == 3:\n",
    "            images = images.unsqueeze(0)\n",
    "\n",
    "        if self._targeted:\n",
    "            labels = self._get_target_label(images, labels)\n",
    "\n",
    "        x_bounds = tuple(\n",
    "            [max(1, d if isinstance(d, int) else round(images.size(3) * d))\n",
    "             for d in self.p1_x_dimensions])\n",
    "\n",
    "        y_bounds = tuple(\n",
    "            [max(1, d if isinstance(d, int) else round(images.size(2) * d))\n",
    "             for d in self.p1_y_dimensions])\n",
    "\n",
    "        adv_images = []\n",
    "\n",
    "        images = images.clone().detach().to(self.device)\n",
    "        labels = labels.clone().detach().to(self.device)\n",
    "\n",
    "        bs, _, _, _ = images.shape\n",
    "\n",
    "        for idx in range(bs):\n",
    "            image, label = images[idx:idx + 1], labels[idx:idx + 1]\n",
    "\n",
    "            best_image = image.clone()\n",
    "\n",
    "            loss, callback = self._get_fun(image, label,\n",
    "                                           target_attack=self._targeted)\n",
    "\n",
    "            best_p = loss(solution=image, solution_as_perturbed=True)\n",
    "            image_probs = [best_p]\n",
    "\n",
    "            for it in range(self.max_patches):\n",
    "\n",
    "                (x, y), (x_offset, y_offset) = \\\n",
    "                    self.get_patch_coordinates(image=image,\n",
    "                                               x_bounds=x_bounds,\n",
    "                                               y_bounds=y_bounds)\n",
    "\n",
    "                destinations = self.get_pixel_mapping(image, x, x_offset,\n",
    "                                                      y, y_offset,\n",
    "                                                      destination_image=best_image)\n",
    "\n",
    "                solution = [x, y, x_offset, y_offset] + destinations\n",
    "\n",
    "                pert_image = self._perturb(source=image,\n",
    "                                           destination=best_image,\n",
    "                                           solution=solution)\n",
    "\n",
    "                p = loss(solution=pert_image, solution_as_perturbed=True)\n",
    "\n",
    "                if p < best_p:\n",
    "                    best_p = p\n",
    "                    best_image = pert_image\n",
    "\n",
    "                image_probs.append(best_p)\n",
    "\n",
    "                if callback(pert_image, None, True):\n",
    "                    best_image = pert_image\n",
    "                    break\n",
    "\n",
    "            adv_images.append(best_image)\n",
    "\n",
    "        adv_images = torch.cat(adv_images)\n",
    "\n",
    "        return adv_images\n",
    "\n",
    "    def _get_prob(self, image):\n",
    "        out = self.model(image.to(self.device))\n",
    "        prob = softmax(out, dim=1)\n",
    "        return prob.detach().cpu().numpy()\n",
    "\n",
    "    def loss(self, img, label, target_attack=False):\n",
    "\n",
    "        p = self._get_prob(img)\n",
    "        p = p[np.arange(len(p)), label]\n",
    "\n",
    "        if target_attack:\n",
    "            p = 1 - p\n",
    "\n",
    "        return p.sum()\n",
    "\n",
    "    def get_patch_coordinates(self, image, x_bounds, y_bounds):\n",
    "        c, h, w = image.shape[1:]\n",
    "\n",
    "        x, y = np.random.uniform(0, 1, 2)\n",
    "\n",
    "        x_offset = np.random.randint(x_bounds[0],\n",
    "                                     x_bounds[1] + 1)\n",
    "\n",
    "        y_offset = np.random.randint(y_bounds[0],\n",
    "                                     y_bounds[1] + 1)\n",
    "\n",
    "        x, y = int(x * (w - 1)), int(y * (h - 1))\n",
    "\n",
    "        if x + x_offset > w:\n",
    "            x_offset = w - x\n",
    "\n",
    "        if y + y_offset > h:\n",
    "            y_offset = h - y\n",
    "\n",
    "        return (x, y), (x_offset, y_offset)\n",
    "\n",
    "    def get_pixel_mapping(self, source_image, x, x_offset, y, y_offset,\n",
    "                          destination_image=None):\n",
    "        if destination_image is None:\n",
    "            destination_image = source_image\n",
    "\n",
    "        destinations = []\n",
    "        c, w, h = source_image.shape[1:]\n",
    "        source_image = source_image[0]\n",
    "\n",
    "        if self.pixel_mapping == 'random':\n",
    "            for i in range(x_offset):\n",
    "                for j in range(y_offset):\n",
    "                    dx, dy = np.random.uniform(0, 1, 2)\n",
    "                    dx, dy = int(dx * (w - 1)), int(dy * (h - 1))\n",
    "                    destinations.append([dx, dy])\n",
    "        else:\n",
    "            for i in np.arange(y, y + y_offset):\n",
    "                for j in np.arange(x, x + x_offset):\n",
    "                    pixel = source_image[:, i: i + 1, j: j + 1]\n",
    "                    diff = destination_image - pixel\n",
    "                    diff = diff[0].abs().mean(0).view(-1)\n",
    "\n",
    "                    if 'similarity' in self.pixel_mapping:\n",
    "                        diff = 1 / (1 + diff)\n",
    "                        diff[diff == 1] = 0\n",
    "\n",
    "                    probs = torch.softmax(diff, 0).cpu().numpy()\n",
    "\n",
    "                    indexes = np.arange(len(diff))\n",
    "\n",
    "                    pair = None\n",
    "\n",
    "                    linear_iter = iter(sorted(zip(indexes, probs),\n",
    "                                              key=lambda pit: pit[1],\n",
    "                                              reverse=True))\n",
    "\n",
    "                    while True:\n",
    "                        if 'random' in self.pixel_mapping:\n",
    "                            index = np.random.choice(indexes, p=probs)\n",
    "                        else:\n",
    "                            index = next(linear_iter)[0]\n",
    "\n",
    "                        _y, _x = np.unravel_index(index, (h, w))\n",
    "\n",
    "                        if _y == i and _x == j:\n",
    "                            continue\n",
    "\n",
    "                        pair = (_x, _y)\n",
    "                        break\n",
    "\n",
    "                    destinations.append(pair)\n",
    "\n",
    "        return destinations\n",
    "\n",
    "    def _get_fun(self, img, label, target_attack=False):\n",
    "        img = img.to(self.device)\n",
    "\n",
    "        if isinstance(label, torch.Tensor):\n",
    "            label = label.cpu().numpy()\n",
    "\n",
    "        @torch.no_grad()\n",
    "        def func(solution,\n",
    "                 destination=None,\n",
    "                 solution_as_perturbed=False, **kwargs):\n",
    "\n",
    "            if not solution_as_perturbed:\n",
    "                pert_image = self._perturb(source=img,\n",
    "                                           destination=destination,\n",
    "                                           solution=solution)\n",
    "            else:\n",
    "                pert_image = solution\n",
    "\n",
    "            p = self._get_prob(pert_image)\n",
    "            p = p[np.arange(len(p)), label]\n",
    "\n",
    "            if target_attack:\n",
    "                p = 1 - p\n",
    "\n",
    "            return p.sum()\n",
    "\n",
    "        @torch.no_grad()\n",
    "        def callback(solution,\n",
    "                     destination=None,\n",
    "                     solution_as_perturbed=False,\n",
    "                     **kwargs):\n",
    "\n",
    "            if not solution_as_perturbed:\n",
    "                pert_image = self._perturb(source=img,\n",
    "                                           destination=destination,\n",
    "                                           solution=solution)\n",
    "            else:\n",
    "                pert_image = solution\n",
    "\n",
    "            p = self._get_prob(pert_image)[0]\n",
    "            mx = np.argmax(p)\n",
    "\n",
    "            if target_attack:\n",
    "                return mx == label\n",
    "            else:\n",
    "                return mx != label\n",
    "\n",
    "        return func, callback\n",
    "\n",
    "    def _perturb(self, source, solution, destination=None):\n",
    "        if destination is None:\n",
    "            destination = source\n",
    "\n",
    "        c, h, w = source.shape[1:]\n",
    "\n",
    "        x, y, xl, yl = solution[:4]\n",
    "        destinations = solution[4:]\n",
    "\n",
    "        source_pixels = np.ix_(range(c),\n",
    "                               np.arange(y, y + yl),\n",
    "                               np.arange(x, x + xl))\n",
    "\n",
    "        indexes = torch.tensor(destinations)\n",
    "        destination = destination.clone().detach().to(self.device)\n",
    "\n",
    "        s = source[0][source_pixels].view(c, -1)\n",
    "\n",
    "        destination[0, :, indexes[:, 0], indexes[:, 1]] = s\n",
    "\n",
    "        return destination\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "2956"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 0.0 1 0\n",
      "0 2 0.0 1 0\n",
      "1 3 0.3333333333333333 0 0\n",
      "2 4 0.5 0 0\n",
      "2 5 0.4 1 0\n",
      "3 6 0.5 0 0\n",
      "3 7 0.42857142857142855 1 0\n",
      "4 8 0.5 1 1\n",
      "4 9 0.4444444444444444 1 0\n",
      "5 10 0.5 1 1\n",
      "5 11 0.45454545454545453 1 0\n",
      "6 12 0.5 0 0\n",
      "7 13 0.5384615384615384 0 0\n",
      "7 14 0.5 0 1\n",
      "8 15 0.5333333333333333 0 0\n",
      "9 16 0.5625 0 0\n",
      "10 17 0.5882352941176471 0 0\n",
      "10 18 0.5555555555555556 1 0\n",
      "11 19 0.5789473684210527 0 0\n",
      "11 20 0.55 1 0\n",
      "11 21 0.5238095238095238 0 1\n",
      "12 22 0.5454545454545454 0 0\n",
      "12 23 0.5217391304347826 1 0\n",
      "13 24 0.5416666666666666 0 0\n",
      "skipped\n",
      "14 25 0.56 0 0\n",
      "15 26 0.5769230769230769 0 0\n",
      "16 27 0.5925925925925926 0 0\n",
      "16 28 0.5714285714285714 1 0\n",
      "16 29 0.5517241379310345 1 0\n",
      "17 30 0.5666666666666667 0 0\n",
      "18 31 0.5806451612903226 0 0\n",
      "19 32 0.59375 0 0\n",
      "20 33 0.6060606060606061 0 0\n",
      "20 34 0.5882352941176471 1 0\n",
      "21 35 0.6 0 0\n",
      "21 36 0.5833333333333334 1 0\n",
      "22 37 0.5945945945945946 0 0\n",
      "skipped\n",
      "23 38 0.6052631578947368 0 0\n",
      "24 39 0.6153846153846154 1 1\n",
      "24 40 0.6 1 0\n",
      "skipped\n",
      "25 41 0.6097560975609756 0 0\n",
      "25 42 0.5952380952380952 0 1\n",
      "26 43 0.6046511627906976 0 0\n",
      "27 44 0.6136363636363636 0 0\n",
      "27 45 0.6 1 0\n",
      "28 46 0.6086956521739131 1 1\n",
      "29 47 0.6170212765957447 0 0\n",
      "30 48 0.625 0 0\n",
      "31 49 0.6326530612244898 0 0\n",
      "32 50 0.64 0 0\n",
      "32 50\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from torch import softmax\n",
    "\n",
    "model.eval()\n",
    "pixle = Pixle(x_dimensions=1, y_dimensions=1, model=model, max_iterations=100, restarts=100)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "classes_total = defaultdict(int)\n",
    "classes_attacked = defaultdict(int)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img, y in torch.utils.data.DataLoader(test_dataset,\n",
    "                                               batch_size=1,\n",
    "                                               shuffle=False):\n",
    "        if total == 50:\n",
    "            break\n",
    "\n",
    "        img = img.unsqueeze(1).to(device)\n",
    "\n",
    "        probs = softmax(model(img), dim=1)[0].cpu()\n",
    "        pred = np.argmax(probs).item()\n",
    "\n",
    "        if pred != y.item():\n",
    "            print('skipped')\n",
    "            continue\n",
    "\n",
    "        pert_images = pixle(img, y)\n",
    "        final_prob = softmax(model(pert_images), dim=1)[0].cpu()\n",
    "\n",
    "        pred = np.argmax(final_prob).item()\n",
    "\n",
    "        if pred == y.item():\n",
    "            correct += 1\n",
    "        else:\n",
    "            classes_attacked[y.item()] += 1\n",
    "\n",
    "        classes_total[y.item()] += 1\n",
    "        total += 1\n",
    "\n",
    "        print(correct, total, correct / total,  y.item(), pred)\n",
    "\n",
    "    print(correct, total)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classes_total"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classes_attacked"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}